{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaORIR1UH63A",
        "outputId": "193ec855-a6b8-4395-a762-7fdf626927d7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘robert_frost.txt’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8u4gYEVSGZwZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial = {} # PI -> for the first word\n",
        "first_order = {} #A_ij -> for one preceeding word (only)\n",
        "second_order = {} #A_ijk -> for two or more preceeding words"
      ],
      "metadata": {
        "id": "12gzAbIdGkB_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(s):\n",
        "    return s.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "5rHFDCLAHclh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What add2dict() function actually does:\n",
        "\n",
        "\n",
        "> FOR example: we encounter the lines in the dataset: **'I am happy.'** , **'I am sad.**','**I am content.**', '**I am happy.**','**I am hungry.**','**I am happy.**'\n",
        "\n",
        "We want to populate the second order dictionary. So, as the key, we need to have the previous two words. The mapping will look like this:\n",
        "<pre>\n",
        "{\n",
        "  (\"I\",\"am\"):[\n",
        "              \"happy\",\n",
        "              \"sad\",\n",
        "              \"content\",\n",
        "              \"happy\",\n",
        "              \"hungry\",\n",
        "              \"happy\"\n",
        "  ]\n",
        "}\n",
        "</pre>\n",
        "\n",
        "Which will Later look like this:\n",
        "<pre>\n",
        "{ (\"I\",\"am\"): {\n",
        "              \"happy\":0.5,\n",
        "              \"sad\":0.07,\n",
        "              \"content\":0.35,\n",
        "              \"hungry\":0.87 ....\n",
        "              }\n",
        "  }\n",
        "</pre>"
      ],
      "metadata": {
        "id": "Tam7fKbXJAWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add2dict(dictionary, key, value):\n",
        "    if key not in dictionary:\n",
        "        dictionary[key] = []\n",
        "    dictionary[key].append(value)"
      ],
      "metadata": {
        "id": "Ldp9vZyUIDdK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in open('robert_frost.txt'):\n",
        "    line = remove_punctuation(line.strip().lower())\n",
        "    tokens = line.split()\n",
        "    T = len(tokens)\n",
        "    for i in range(T):\n",
        "      t = tokens[i]\n",
        "      if i == 0:\n",
        "        # measure the probability of the intial state (first word in the sentence/sequence.)\n",
        "        initial[t] = initial.get(t, 0.) + 1\n",
        "      else:\n",
        "        t_1 = tokens[i-1]\n",
        "        if i == T-1:\n",
        "          # measure the probability of ending the line (last word in the sentence/sequence.)\n",
        "          add2dict(second_order, (t_1, t), 'END')\n",
        "        if i ==1:\n",
        "          # measure distribution for second word given first word\n",
        "          add2dict(first_order, t_1,t)\n",
        "        else:\n",
        "          t_2 = tokens[i-2]\n",
        "          add2dict(second_order, (t_2, t_1 ),t)"
      ],
      "metadata": {
        "id": "V3NwsDbhMCjN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalize the distribution\n",
        "initial_sum = sum(initial.values())\n",
        "for t,key in initial.items():\n",
        "    initial[t] = key/initial_sum\n"
      ],
      "metadata": {
        "id": "Yrkx8G__OuAB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def list2pdict(ts):\n",
        "  d = {}\n",
        "  n = len(ts)\n",
        "  for t in ts:\n",
        "    d[t] = d.get(t, 0.) + 1\n",
        "  for t,c in d.items():\n",
        "    d[t] = c/n\n",
        "  return d"
      ],
      "metadata": {
        "id": "-ICqGWcxPI0-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t_1,ts in first_order.items():\n",
        "  first_order[t_1] = list2pdict(ts)"
      ],
      "metadata": {
        "id": "uGmVKIijPpCt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, ts in second_order.items():\n",
        "  second_order[k] = list2pdict(ts)"
      ],
      "metadata": {
        "id": "Qxi2ju4YPvWx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_word(d):\n",
        "  p0 = np.random.random()\n",
        "  cumulative = 0.\n",
        "  for t,p in d.items():\n",
        "    cumulative += p\n",
        "    if p0 < cumulative:\n",
        "      return t"
      ],
      "metadata": {
        "id": "sA0eJ6z3PzQf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate():\n",
        "  for i in range(4):\n",
        "    sentence = []\n",
        "    w0 = sample_word(initial)\n",
        "    sentence.append(w0)\n",
        "    w1 = sample_word(first_order[w0])\n",
        "    sentence.append(w1)\n",
        "\n",
        "    while True:\n",
        "      w2 = sample_word(second_order[(w0, w1)])\n",
        "      if w2 == 'END':\n",
        "        break\n",
        "      sentence.append(w2)\n",
        "      w0 = w1\n",
        "      w1 = w2\n",
        "    print(' '.join(sentence))"
      ],
      "metadata": {
        "id": "t68tDT_fQOb-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWQLkbM_QpzZ",
        "outputId": "faf22ef0-76a8-4aa6-bcaf-bc196875f5cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to tell him everything\n",
            "of country where two village cultures faded\n",
            "he broke my trance dont that make you suspicious\n",
            "and youre her mother\n"
          ]
        }
      ]
    }
  ]
}